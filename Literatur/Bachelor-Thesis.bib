Automatically generated by Mendeley Desktop 1.19.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{TemperoEwanandAnslowCraigandDietrichJensandHanTedandLiJingandLumpeMarkusandMeltonHaydenandNoble2010a,
author = {{Tempero, Ewan and Anslow, Craig and Dietrich, Jens and Han, Ted and Li, Jing and Lumpe, Markus and Melton, Hayden and Noble}, James},
doi = {http://dx.doi.org/10.1109/APSEC.2010.46},
journal = {2010 Asia Pacific Software Engineering Conference (APSEC2010)},
pages = {336----345},
title = {{Qualitas Corpus: A Curated Collection of Java Code for Empirical Studies}},
year = {2010}
}
@article{Sajnani2013,
abstract = {We propose a new token-based approach for large scale code clone detection. It is based on a filtering heuristic which reduces the number of token comparisons. The filtering heuristic is generic and can also be used in conjunction with other token-based approaches. In that context, we demonstrate how it can reduce the index-creation time and memory usage in index-based approaches. We also implement a MapReduce based parallel algorithm that implements the filtering heuristic and scales to thousands of projects. In our two separate experiments, we found that: (i) the total number of token comparisons are reduced by a factor of 10, increasing the speed by a factor of 1.5; and (ii) the Speed-up and Scale-up of the parallel implementation appear to be linear on a cluster of 2-32 nodes for 150-2800 projects.},
author = {Sajnani, Hitesh and Lopes, Cristina},
doi = {10.1109/IWSC.2013.6613042},
file = {:home/ga58lum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sajnani, Lopes - 2013 - A parallel and efficient approach to large scale clone detection.pdf:pdf},
isbn = {978-1-4673-6445-4},
journal = {2013 7th International Workshop on Software Clones (IWSC)},
pages = {46--52},
title = {{A parallel and efficient approach to large scale clone detection}},
url = {http://ieeexplore.ieee.org/document/6613042/},
volume = {7300},
year = {2013}
}
@article{Roy2007,
abstract = {Code duplication or copying a code fragment and then reuse by pasting with or without any modifications is a well known code smell in software maintenance. Several studies show that about 5{\%} to 20{\%} of a software systems can contain duplicated code, which is basically the results of copying existing code fragments and using then by pasting with or without minor modications. One of the major shortcomings of such duplicated fragments is that if a bug is detected in a code fragment, all the other fragments similar to it should be investigated to check the possible existence of the same bug in the similar fragments. Refactoring of the duplicated code is another prime issue in software maintenance although several studies claim that refactoring of certain clones are not desirable and there is a risk of removing them. However, it is also widely agreed that clones should at least be detected. In this paper, we survey the state of the art in clone detection research. First, we describe the clone terms commonly used in the literature along with their corresponding mappings to the commonly used clone types. Second, we provide a review of the existing clone taxonomies, detection approaches and experimental evaluations of clone detection tools. Applications of clone detection research to other domains of software engineering and in the same time how other domain can assist clone detection research have also been pointed out. Finally, this paper concludes by pointing out several open problems related to clone detection research.},
author = {Roy, Chanchal K and Cordy, James R},
doi = {10.1.1.62.7869},
file = {:home/ga58lum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy, Cordy - 2007 - A Survey on Software Clone Detection Research.pdf:pdf},
isbn = {978-963-9995-24-6},
journal = {Queen's School of Computing TR},
pages = {115},
title = {{A Survey on Software Clone Detection Research}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.7869{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.9931{\&}rep=rep1{\&}type=pdf},
volume = {115},
year = {2007}
}
@article{Alves2011,
abstract = {The categorization of source code artifacts affects how the overall product is measured and consequently how these measurements are interpreted. When measuring complexity, for instance, failing to distinguish test and generated code will affect complexity measurements possibly leading to an erroneous interpretation of the overall product complexity. Although categorization problems are known, there seems to be little attention given to this subject in the literature. In this paper, we introduce a categorization for source code artifacts and present an empirical study providing evidence of each category. Artifacts are divided into production and test code, and then these categories are sub-divided into manually-maintained, generated, library, and example code. By analyzing 80 Java and C{\#} industrial systems, we have found evidence of the majority of categories. We show that in average production code only accounts for 60{\&}{\#}x025; of a product volume. Also, we have found that for some systems the overall percentage of test and generated code, each can account to over 70{\&}{\#}x025; and of library code to over 40{\&}{\#}x025;. Finally we discuss the difficulties of distinguishing source code artifacts and conclude with directions for further research.},
author = {Alves, Tiago L},
doi = {10.1109/ESEM.2011.42},
file = {:home/ga58lum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alves - 2011 - Categories of Source Code in Industrial Systems.pdf:pdf},
isbn = {978-0-7695-4604-9},
issn = {1938-6451},
journal = {2011 International Symposium on Empirical Software Engineering and Measurement},
keywords = {Categorization,analysis scope,industrial systems,product measurement,software metrics,source code},
pages = {335--338},
title = {{Categories of Source Code in Industrial Systems}},
year = {2011}
}
@article{Ukkonen1993,
abstract = {The classical approximate string-matching problem of finding the locations of approximate occurrences P of pattern string P in text string T such that the edit distance between P and P is k is considered. We concentrate on the special case in which T is available for preprocessing before the searches with varying P and k. It is shown how the searches can be done fast using the suffix tree of T augmented with the suffix links as the preprocessed form of T and applying dynamic programming over the tree. Three variations of the search algorithm are developed with running times O(mq + n), O(mq log q + size of the output), and O(m 2 q + size of the output). Here n = ¦T¦, m = ¦P¦, and q varies depending on the problem instance between 0 and n. In the case of the unit cost edit distance it is shown that q = O(min(n, m k+1¦¦ k )) where is the alphabet.},
author = {Ukkonen, Esko},
doi = {10.1007/BFb0029808},
file = {:home/ga58lum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ukkonen - 1993 - Approximate string-matching over suffix trees.pdf:pdf},
isbn = {3-540-56764-X},
issn = {0926-9630},
journal = {Combinatorial Pattern Matching},
pages = {228--242},
pmid = {11604874},
title = {{Approximate string-matching over suffix trees}},
url = {http://www.springerlink.com/index/5135X125134V4450.pdf{\%}5Cnpapers2://publication/uuid/0AE55FED-584F-43DF-9071-60901AB34DD5},
year = {1993}
}
@article{Bernwieser2014,
author = {Bernwieser, Jonathan},
file = {:home/ga58lum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bernwieser - 2014 - Automatic Categorization of Source Code in Open-Source Software.pdf:pdf},
title = {{Automatic Categorization of Source Code in Open-Source Software}},
year = {2014}
}
@misc{ApacheSoftwareFoundation,
abstract = {For Creating Scalable Performant Machine Learning Applications},
author = {{Apache Software Foundation}},
title = {{Mahout}},
url = {https://mahout.apache.org/}
}
@article{Ukkonen1995,
abstract = {An on–line algorithm is presented for constructing the suﬃx tree for a given string in time linear in the length of the string. The new algorithm has the desirable property of processing the string symbol by symbol from left to right. It has always the suﬃx tree for the scanned part of the string ready. The method is developed as a linear–time version of a very simple algorithm for (quadratic size) suﬃx tries. Regardless of its quadratic worst-case this latter algorithm can be a good practical method when the string is not too long. Another variation of this method is shown to give in a natural way the well–known algorithms for constructing suﬃx automata (DAWGs)},
author = {Ukkonen, E.},
doi = {10.1007/BF01206331},
file = {:home/ga58lum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ukkonen - 1995 - On-line construction of suffix trees.pdf:pdf},
issn = {01784617},
journal = {Algorithmica},
keywords = {DAWG,Linear-time algorithm,Suffix automaton,Suffix tree,Suffix trie},
number = {3},
pages = {249--260},
title = {{On-line construction of suffix trees}},
volume = {14},
year = {1995}
}
@article{Ukkonen1992,
abstract = {We study approximate string-matching in connection with two string distance functions that are computable in linear time. The first function is based on the so-called q-grams. An algorithm is given for the associated string-matching problem that finds the locally best approximate occurrences of pattern P, ∣P∣ = m, in text T, ∣T∣ = n, in time O(n log (m–q)). The occurrences with distance ⩽k can be found in time O(n log k). The other distance function is based on finding maximal common substrings and allows a form of approximate string-matching in time O(n). Both distances give a lower bound for the edit distance (in the unit cost model), which leads to fast hybrid algorithms for the edit distance based string-matching.},
author = {Ukkonen, Esko},
doi = {https://doi.org/10.1016/0304-3975(92)90143-4},
file = {:home/ga58lum/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ukkonen - 1992 - Approximate String Matching with q-grams and Maximal Matches.pdf:pdf},
issn = {0304-3975},
journal = {Theor. Comput. Sci.},
number = {1},
pages = {191--211},
title = {{Approximate String Matching with q-grams and Maximal Matches}},
volume = {92},
year = {1992}
}
