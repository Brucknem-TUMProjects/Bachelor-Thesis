% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Approach}\label{chapter:approach}
The research question studied in this thesis is the prototypical implementation of heuristics to detect generated code which use techniques of clone detection on the comments that are extracted from the source code. A list of heuristics that detect generated code of several code generators will be derived by means of the comments. Therefore a generator pattern repository will be created. The target of this repository is to provide a database of code generators and their respective characteristic generator pattern which identifies the source code containing it as generated.\\
For the use in this thesis a Teamscale server is used which performs basic analysis tasks on the specified projects.
\section{Use Teamscale as Lexer to extract Tokens}
The first step in the approach used in this paper is the lexical analysis of the source code included in the projects used as a benchmark. Teamscale comes with a multitude of lexers applicable for many different programming languages. The general workflow in this step is reading each source code file found in the project, perform the lexical analysis and tokenize the source code file into a sequence of logically coherent tokens representing the source code on a logical level. The tokens are saved server-side in the Teamscale instance.
\begin{center}
	\begin{tikzpicture}[scale=2, node distance = 4cm, auto]
\node [block] (init) {Source Code File};
\node [block, right of=init] (lexer) {Lexical Analysis};
\node [block, right of=lexer] (tokens) {Sequence of Tokens};
% Draw edges
\path [line] (init) -- (lexer);
\path [line] (lexer) -- (tokens);
\end{tikzpicture}
\end{center}

\section{Connect to the Teamscale server and retrieve comments}
\label{chapter_retrieveComments}
In the second step the tool written for this thesis connects to the Teamscale instance and retrieves the comments.\\
This has to be done in the following steps:
\begin{enumerate}
	\item Get the projects that are currently available in the Teamscale instance. 
	\item For each project retrieve the respective uniform paths to access the source code files on the server.
	\item For each uniform path retrieve the comments that are included in the respective source code file. In this step the server filters all tokens that are available for each file. The only important token class is the \textit{COMMENT} class, which itself contains the sub-classes shown in Table \ref{table_commentTypes}.
	\item The local file path of every source code file is retrieved from the server based on the uniform path. This will get important later in the evaluation.
	\item Each local file path gets associated to the respective list of comments.
\end{enumerate}

\begin{tikzpicture}[scale=2, node distance = 3cm, auto]
	\node [block] (init) {Get Projects};
	\node [block, right of=init] (uniforms) {Retrieve Uniform Paths};
	\node [block, right of=uniforms] (filter) {Filter and Transfer Comments};
	\node [block, right of=filter] (local) {Get Local File Paths};
	\node [block, right of=local] (associate) {Associate Path to Comments};
	
	\path [line] (init) -- (uniforms);
	\path [line] (uniforms) -- (filter);
	\path [line] (filter) -- (local);
	\path [line] (local) -- (associate);
\end{tikzpicture}
 
\begin{table}[H]
	\caption{Comment types}
	\label{table_commentTypes}
	\begin{tabularx}{\textwidth}{l|L}
		\textbf{Token type} & \textbf{Example} \\
		\hline
		HASH\_COMMENT & \textit{\# Sample PHP script accessing HyperSQL through the ODBC extension module.}\\ 
		DOCUMENTATION\_COMMENT & \textit{/** Generated By:JJTree: Do not edit this line. */} \\ 
		SHEBANG\_LINE & \textit{\#!/usr/bin/env python } \\ 
		TRIPLE\_SLASH\_DIRECTIVE & \textit{/// <reference path="Parser.ts" />} \\ 
		TRADITIONAL\_COMMENT & \textit{/* Do not modify this code */} \\ 
		MULTILINE\_COMMENT & \textit{"""Testsuite for TokenRewriteStream class."""} \\ 
		END\_OF\_LINE\_COMMENT & \textit{// don't care about docstrings} \\ 
		SIX\_COLUMNS\_COMMENT & \textit{\dots} \\ 
	\end{tabularx} 
\end{table}


\section{Prepare comments for suffix tree clone detection}
Once the comments are received from the Teamscale server instance they have to get prepared to be usable in the suffix tree clone detection as introduced by Esko Ukkonen \cite{Ukkonen1995}\cite{Ukkonen1993}.\\
\subsection{Create thread for each source code file}
The step \ref{chapter_retrieveComments} produces a \textit{Map} in which every local path to a source code file is associated with its respective list of comments.
In the first part of the preparation one thread is generated for each source code file respective local file path. These threads will be responsible for the preparation of each single file and the results will be merged at the end.
\subsection{Remove unnecessary characters and whitespaces}
At first the comments are split at the linebreaks into single lines and leading and trailing whitespaces of each line are removed.\\
Susequent the comment enclosings are removed using a regular expression on every line to remove the language specific identifiers of comments. This regular expression is build from a list of regular expressions that represent the specific comment enclosings in the respective language.\\ 
These are concatenated with the \textit{OR}-operator to generate a generic regular expression for most programming language supported by Teamscale (\ref{chapter_teamscale}). Following this step the the leading and trailing whitespaces are removed again.\\
An overview of the regular expressions that are used in this step are shown in table \ref{table_commentEnclosings}.

\begin{table}
	\caption{Programming language specific regular expressions that represent comment identifiers (Escape characters are omitted).}
	\label{table_commentEnclosings}
	\begin{tabularx}{\textwidth}{l|L}
		\textbf{Programming language(s)} & Regular expression \\
		\hline
		C-like & ((\textasciicircum(/**|/*|*|//))|(*/)\$) \\
		Ada & (\textasciicircum(--)) \\
		Matlab & (\textasciicircum(\%)) \\
		Python & (\textasciicircum(\#)) \\
		XML & ((\textasciicircum(<!-{}-))|(-{}->)\$)
	\end{tabularx}
\end{table}

\subsection{Convert words into clone chunks}
The resulting lines of the previous step are again split into single words. Every word is at first checked if it holds valuable information for the approach. To check the value of each word it gets checked if it contains alphabetic letters \textit{(a-z, A-Z)} or digits. If a word only consists of nonalphabetic and no digits it gets sorted out \textit{(e.g. "-{}-{}-{}-{}-{}-{}-{}-")}.\\
The remaining words that bring a value to the approach are now converted into clone chunks. Therefore is added to every word the type of the comment, the offset and the linenumber of the comment and the local file path the comment originated from.\\
For an overview over these properties of a comment see \ref{subsection_token}.

\subsection{Add sentinels}
To prevent the suffix tree clone detection algorithm from intermixing the comments a sentinel gets added at the end of the list of clone chunks resulting from the previous steps. This is necessary due to the fact that the algorithm works an a single list of clone chunks that is build from merging all clone chunks from every comment.

\section{Build suffix tree}
\section{Find clones}
\section{Filter possibly generated clone results}
\section{Generate links to the files}
\section{Generation of a Generator-Pattern Repository}