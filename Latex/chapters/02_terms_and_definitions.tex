% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Terms and Definitions}\label{chapter:terms}

\section{Terminology}
\subsection{Generated code}
--- Copied ---\\
As proposed in \cite{Alves2011} we consider \textit{generated code} all artifacts that are automatically created and modified by a tool using other artifacts as input. Common examples are parsers (generated from grammars), data access layers (generated from different models such as UML, database schemas or web-service specifications), mock objects or test code.

\subsection{Manually-maintained code}
--- Copied ---\\
In contrast we consider \textit{manually-maintained code} as suggested in \cite{Alves2011} all artifacts that have been created or modified by a developer either under development or maintenance. This includes all artifacts created using any type of tool (e.g. editor). Configuration, experimental or temporary artifacts, if created or modified by a developer, should also be considered as \textit{manually-maintained code}.
\subsection{Generator pattern}
As a \textit{generator pattern} we consider all comments that a code generator adds to the generated artifacts during generation and that distinguish generated from manually-maintained code. Most code generators do add generator patterns that are characteristic for the generator and identify the code as generated. This includes header comments preceding entire source code files as well as comments that mark single functions.

\subsection{Generator pattern repository}
The \textit{generator pattern repository} is the target of this thesis. It will be a database holding the generator patterns associated to its generator and the scope that the pattern denotes as generated.

\subsection{Clone}
We refer to \textit{clones} in the context of this thesis as text fragments that have two or more instances in comments. This includes whole comments that are identical in different source code files as well as parts of comments. The original and the duplicated fragment build a clone pair \cite{Roy2007}. 

\subsection{Clone chunk}
For the use in Ukkonens algorithm for the construction of a suffix tree \cite{Ukkonen1995} the text of the comments has to be normalized in \textit{clone chunks}. The suffix tree clone detection approach uses a sequence of clone chunks and constructs the tree on them. To be suitable each comment is split in separate words, whereas additional information gets appended to each word that will later on be used to identify the origin. This information includes the uniform path to the original source code file, the line number in which the word originated and the programming language.

\subsection{Clone class}
\input{tables/clonePair_cloneClass.tex}

A \textit{clone class} is the maximal set of comments in which any two of the comments form a clone pair.\\
Table \ref{table:cloneClass} depicts an example of the appearance of 3
clone classes: i) $<F1(b), F2(b), F3(a)>$, where the three code portions $F1(b), F2(b)$ and $F3(a)$ form clone pairs with each other, ii) $<F1(a), F2(a)>$, and iii) $<F2(c), F3(c)>$ \cite{Bernwieser2014}.


 

\subsection{Clone result}




\section{Metrics}
\subsection{Lines of code}
As stated in \cite{Bernwieser2014} the \textit{Lines of Code (LOC)} metric represents the size of a software and is thus one of the easiest ways to represent its complexity. Generally the LOC metric does not provide very meaningful results as code quality does not correlate with the number of lines; it’s still useful in order to give an impression about a class’ size and thus its respective impact on the overall quality.
\subsection{Clone coverage}
\textit{Clone coverage }is an important metric to reflect the maintainability
and the extendibility of a software. It defines the probability that an arbitrarily chosen statement is part of a clone. If the clone rate is too high, it can be very dangerous to implement changes as they have to be performed on every clone.
\subsection{Comment ratio}

\section{Teamscale}
\label{section:teamscale}
\textit{Teamscale} is developed by the CQSE GmbH which was founded in 2009 as spin-off of Technical University Munich (TUM). They offer innovative consulting and products to help their customers evaluate, control and improve their software quality. \\
Their main product is Teamscale which is a tool to analyze the quality of code with a variety of static code analyses. It helps to monitor the quality of code over time and is personally configurable to allow users to focus on personal quality goals and keep an eye on the current quality trend.\\
The supported programming languages of Teamscale are \textit{ABAP, Groovy, Matlab, Simulink/StateFlow, Ada, Gosu, Open CL, SQLScript, C\#, IEC 61131-3 ST, OScript, Swift, C/C++, Java, PHP, TypeScript, Cobol, JavaScript, PL/SQL, Visual Basic .NET, Delphi, Kotlin, Python, Xtend, Fortran, Magik and Rust}.\\
One major aspect in the quality analysis performed by Teamscale is the \textit{Clone Detection}. With it duplicated code created by copy \& paste can be found automatically.
\subsection{Suffix Tree Clone Detection}
In \cite{Ukkonen1995}, an on-line algorithm is presented for constructing the suffix tree for a given string in time linear in the length of the string. Based on this data structure a string-matching algorithm is presented in \cite{Ukkonen1993}. These two algorithms have been extended to be usable in this thesis to detect clones among comments in source code.
\subsection{Lexer}
A second important aspect that is included in Teamscale are the lexers for a variety of programming languages. A tokenizer, also called lexical scanner (short: \textit{Lexer}) is a programm that splits plain text in a sequence of logical concatenated units, so called tokens. The plain text tokenized by the lexer can be anything, but we will restrict it to source code.
\subsection{Token}
\label{section:token}
Tokens in the context of Teamscale are objects that are returned as a sequence by the lexer. They provide a data structure holding the main properties of the smallest possible units a source code file can be split. An overview of these properties is shown in Table \ref{table:tokenProperties}.
\input{tables/tokenProperties.tex}

\subsection{Token class}
A token is always an element of one of the token classes \textit{LITERAL, KEYWORD, IDENTIFIER, DELIMITER, COMMENT, SPECIAL, ERROR, WHITESPACE} or \textit{SYNTHETIC}. These are mutually exclusive sets that wrap all possible types a token can adopt.

\subsection{Token type}
A token always adopts one single type. These range from the simple \textit{INTEGER\_LITERAL} over \textit{HEADER} to \textit{DOCUMENTATION\_COMMENT}.
