% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Evaluation}\label{chapter:evaluation}
\section{Tasks to evaluate}

\subsection{Evaluation of the completeness and accuracy of the produced heuristics against a reference data set}
To evaluate the completeness and accuracy of the heuristics produced during the development of this thesis a reference data set has been used.\\
We implemented a procedure to check all files in the projects whether it contains a generator-pattern. These files are separately saved in a list and reviewed randomly for their amount of false positives. \\
Bernwieser~\cite{Bernwieser2014} provided a list of files that he detected as generated to us, to witch our results are compared against. \\
We do this to evaluate whether the approach given in this thesis is an improvement to the existing ones, especially the one given by~\cite{Bernwieser2014}. It resolves whether the generator-pattern repository can be used as a database in production while performing static code analysis.

\subsection{Automatic classification of source code in a huge collection of open source systems \& evaluation of the ratio of generated code}
To test the generator patterns stored in the repository a variety of open source projects have been acquired.\\
These projects have been filtered using the generator-pattern repository to detect the amount of generated code in a huge, randomly composed collection of open source systems.\\
We calculated the amount of generated code in these projects to evaluate the usage of code generators and their importance in programming. 

\section{Study Objects}
We used different study objects to test the approach used in this thesis and to evaluate the completeness and accuracy of the generator-pattern repository. \\
A reference data set is described in Section~\ref{section:qualitasCorpus} which includes good documented code, whereas Section~\ref{section:randomGitProjects} describes a randomly composed collection of open source projects that is used to test the generator-pattern repository in a not particularly curated environment.
 
\subsection{Qualitas Corpus}
\label{section:qualitasCorpus}
"The Qualitas Corpus is a curated collection of software systems intended to be used for empirical studies of code artefacts. The primary goal is to provide a resource that supports reproducible studies of software. The current release of the Corpus contains open-source Java software systems, often multiple versions." \cite{TemperoEwanandAnslowCraigandDietrichJensandHanTedandLiJingandLumpeMarkusandMeltonHaydenandNoble2010a}\\
Nonetheless the procedure is designed to be also applicable onto sets including other programming languages as well as sets of projects with mixed ones.\\
The current release is from the year 2013 and includes 112 different projects. To be easily comparable to the work in \cite{Bernwieser2014}, we also added the project Mahout~\cite{ApacheSoftwareFoundation}.\\
Additionally, we could perform the analysis on all projects so we didn't have to exclude \textit{eclipse\_SDK} nor \textit{netbeans}.\\
Table~\ref{table:qualitasCorpusAll} displays all projects that are included in the Qualitas Corpus together with their amount of lines of code. The size of the projects ranges from 6.991 \textit{(fitjava)} up to 7.142.778 \textit{(netbeans)}.
\input{tables/qualitasCorpusAll.tex}
%the same two subsets of projects have been reused. The classification of the projects included in the two sets has been made in \cite{Bernwieser2014}, whereas one consists of projects including generated code and the other fully excluding this type of source code.\\
%Both collections show a very wide variation range regarding their project sizes; projects with generated code range from 35.388 \textit{(SableCC)} to 1.540.009 \textit{(GT2)}, projects without generated code from 29.587 \textit{(Informa)} to 645.715 \textit{(Jtopen)} \cite{Bernwieser2014}. 
%The project \textit{Mahout} has been replaced by \textit{Xalan} because it isn't included in the Qualitas Corpus anymore.\\ 
%The distribution of the projects over the environments is shown in Table~\ref{table:qualitasCorpusOverview}.
%\input{tables/qualitasCorpusOverview.tex}

\subsection{Random Git Projects}
\label{section:randomGitProjects}
To collect a huge, randomly composed collection of open source projects a git crawler has been implemented.
By passing a keyword to the crawler it queries \href{github.com}{GitHub} to return project descriptions of projects that contain the keyword in their names or descriptions. From the received project descriptions the links to clone the projects are extracted. The projects are cloned and saved sorted by their programming languages, whereas the crawler queries for projects written in all languages supported by Teamscale to provide the highest level of randomness and diversity for the projects.
\annotation{Describe more}

\section{Study Design}
\annotation{This section describes how the study, using the information from the study objects, attempts to answer the research questions.}

To evaluate the completeness and accuracy of the produced heuristics we used the Qualitas Corpus to calculate the amount of generated code. Using this information we compared our results to the ones provided in \cite{Bernwieser2014} to derive the improvement our approach makes in distinguishing generated from manually maintained code.\\
Based on the set of generated source code files we calculated different metrics:
\begin{itemize}
	\item Lines of code for generated and manually maintained source code.
	\item Number of generated and manually maintained source code files.
	\item Ratio of generated to manually maintained source code and files.
	\item Amount of generated code detected by our approach compared to the one used in \cite{Bernwieser2014}.
\end{itemize}

\section{Procedure}
This section justifies the decisions we made for the different thresholds as well as our decision to highly multithread the different steps used in the approach.

\subsection{Testing environment}
The benchmarks are performed on an \textit{Intel Core i7-6700HQ CPU} running with a frequency of \textit{2.60GHz} on \textit{four} physical cores with \textit{40GB RAM}. To run the Java Code we used the \textit{Eclipse IDE} \annotation{Cite} executed on \textit{Ubuntu 18.04.1 LTS (64-bit)} based on the \textit{4.15.0-33-generic} Kernel.\\
We compare the durations of the single steps performed during the suffix-tree clone-detection approach to find generator-patterns. We used the projects \textit{azureus, batik, checkstyle, cobertura, compiere, derby, drjava, exoportal, freecol, freecs, galleon, hsqldb, htmlunit, ireport, ivatagroupware, jFin\_DateMath, javacc, jedit, jgrapht, jhotdraw, jmoney, joggplayer, jparse, jspwiki, jstock, jung, maven, netbeans, openjms, oscache, quilt, sandmark, squirrel\_sql, tapestry, trove, weka, xerces} as a reference benchmark environment and ran the procedure several times to calculate a solid average value for the durations. \\
The decision for this environment is reasoned by its size of 37~projects including 60.235~source code files, whereas 3034~files are generated. It contains a total of 1.166.654~comments with a total of 23.683.887~valuable words. This pushes the machine the benchmark has been performed on to its maximum heap space it can provide to the Java Virtual Machine. The projects are chosen randomly to provide a meaningful mean of projects to preserve the generality of the Qualitas Corpus.

\subsection{Thresholds}
The threshold that has a direct impact on the number of found generator-patterns is the minimum clone length. It describes the minimal length a sequence of \code{CloneChunk}s has to provide to be considered by the Step~\ref{section:findClones}. If a sequence is shorter than the minimum clone length it will not be added to the list of clone classes independent of the size the clone class would have.\\
Finding the best minimum clone length has been done by performing tests with different clone lengths ranging from a length of 2\footnote{We didn't start at 1 because single words aren't meaningful when searching for generator-patterns. Especially words like \textit{the, a, by \dots} would have many occurrences that generate a huge amount of false positive clone classes.} up to a length of 25.\\
We finally decided on the minimum clone length of 5, where as the choice has been a mostly subjective one. Nonetheless did we consider the draw-off between the amount of results that are lost due to a to high minimum clone length and the amount of irrelevant data generated by a to low minimum clone length.\\
Figure~\ref{fig:thresholdsAll} shows all found \code{CloneResult}s associated to the minimum clone length used to find it. It can be seen that by increasing the minimum clone length the number of \code{CloneResult}s drops nearly exponentially. \\
After applying the processing steps described in Step~\ref{section:processCloneResults} to reduce the amount of data that is created, the remaining \code{CloneResult}s behave as shown in Figure~\ref{fig:thresholdsProcessed}. It shows that by filtering the amount of \code{CloneResult}s drops by around 99\%, dropping even further by accumulating and clustering.\\
We tried using the minimum clone length of 3 at first due to the peak in the remaining \code{CloneResult}s. Nonetheless did we decide to use 5 because the observation was that no generator-patterns were lost by using this minimum clone length, but the manual search for the patterns in the links was much easier because the sequences were more meaningful.
\input{figures/Thresholds/thresholdAll.tex}
\input{figures/Thresholds/thresholdProcessed.tex}

\subsection{Benchmarking}
\label{section:benchmark}
As displayed in Figure~\ref{fig:benchmark}, the time-intensive steps are multithreaded.\\
We performed the benchmark with a minimum clone length of 5.\\
This results in time savings ranging from 5.32\% \textit{(Get Uniform Paths)} up to 86.25\% \textit{(Create Links For: GENERATED)}. The overall time saving sums up to a total of 56.5\%, which reduces the average absolute amount of time of around 300 seconds down to 130 seconds. 
\input{figures/Benchmark/benchmark.tex}
\input{tables/tickLabels.tex}

\section{Results}
This section displays the results we were able to create by using the approach to find generator-patterns and by using the the resulting generator-pattern repository on the different data sets. 
\subsection{Qualitas Corpus}
At first we considered the Qualitas Corpus because it provided a good database and the results can be compared to the ones made in \cite{Bernwieser2014}.\\
We found a total of 41 from the 112 projects to contain generated code. 

\subsubsection{Number of generator-patterns found}
A total of 48 generator-patterns have been found. They are generated by 29 different generators. Additionally most of the patterns are regular expressions that accept up to 32 different patterns so that the final number of found generator patterns is much higher.

\input{figures/QualitasCorpusComparison/comparison.tex}
\subsubsection{Lines of code for generated and manually maintained source code.}
\label{section:qualitasCorpusLOC}
The Table~\ref{table:locQualitasCorpus} shows how many \textit{lines of code} fall into the categories of generated and manually maintained code augmented with the ratios the categories cover. The ratio in lines of code for generated source code range from very low values \textit{(0,05\% - Hibernate)} up to more than three fourth \textit{(75,03\% - Cobertura)} of the overall lines of code.\\
Additionally, the Figure~\ref{fig:comparison} displays the accumulated ratios of generated and manually maintained lines of code.\\
The average proportion of generated lines of code is calculated using the equation
\begin{equation}
	\label{eq:locAvg}
	LOC_{avg} = \frac{\mathlarger{\sum^{projects} \frac{LOC_{generated}}{LOC}}}{|projects|} = 13.95\%
\end{equation}
The total proportion of generated lines of code is calculated via
\begin{equation}
	\label{eq:locTotal}
	LOC_{total} = \frac{\mathlarger{\sum^{projects} LOC_{generated}}}{\mathlarger{\sum^{projects} LOC}} = 7.96\%
\end{equation} 
The average and total proportions of manually maintained lines of code are described by the complementary probability.

\input{tables/locQualitasCorpus.tex}

\subsubsection{Number of generated and manually maintained source code files.}
Table~\ref{table:countQualitasCorpus} additionally displays the \textit{number of source code files} that are generated next to the ones that are manually maintained. The ratios the code categories cover are again associated to the absolute values, whereas they range from a very small amount of files \textit{(0,02\% - Hibernate)} up to around two third \textit{(68,18\% - SableCC)}.\\
Analog to the calculation of the total and the average ratios of generated to manually maintained lines of code as described in in Section~\ref{section:qualitasCorpusLOC} are the proportions of generated to manually maintained files calculated. The same equations~\ref{eq:locAvg}~and~\ref{eq:locTotal} are used, but LOC is replaced by the number of files. Figure~\ref{fig:comparison} displays the ratios.\\
This resulted in $Files_{avg} = 8.07\%$ and $Files_{total} = 5.19\%$.\\
Again, the average and total proportions of manually maintained files are described by the complementary probability.

\input{tables/countQualitasCorpus.tex}

\subsubsection{Lines of code per source code file}
When looking at the Tables~\ref{table:countQualitasCorpus}~and~\ref{table:locQualitasCorpus} we saw that in many projects only a few generated files are responsible for a high number in lines of code.\\
We decided to calculate the proportion of lines of code per file for the generated and the manually maintained files and could confirm that there exists indeed a correlation between the file size and the possible generation as stated in~\cite{Bernwieser2014}.\\
We calculated a \textbf{total} ratio of generated lines of code to generated files of 
\begin{equation}
	\frac{LOC_{generated}}{Files_{generated}} = 321 , \quad \frac{LOC_{manually}}{Files_{manually}} = 204
\end{equation}
and an \textbf{average} ratio of
\begin{equation}
	\frac{LOC_{generated}}{Files_{generated}} = 694 , \quad \frac{LOC_{manually}}{Files_{manually}} = 214
\end{equation}

\subsection{Random Git Projects}
a
\subsubsection{Lines of code for generated and manually maintained source code.}
a
\subsubsection{Number of generated and manually maintained source code files.}
a
\section{Discussion}
By analyzing the projects included in the Qualitas Corpus we found a wide variety of generator-patterns and were able to calculate the average and total proportions of generated to manually maintained lines of code and files. We saw that generated code makes only a small portion of the all lines of code, whereas in average a project contains 13.95\% generated lines of code and all projects contained 7.96\% generated lines of code.\\
Additionally we saw that in average 8.07\% of files are generated whereas in total only 5.19\% are generated.\\
Resulting from that we showed that the average generated file contains more that three times the amount of lines of code (694) as the manually maintained one (214). In total a generated file contains 321 lines of code and a manually maintained one 204.

\subsection{Completeness and accuracy}
We found the generator-patterns by iterating over the Qualitas Corpus and applying the algorithm described in Chapter~\ref{chapter:approach}. The found patterns had been added to the generator-pattern repository and used to filter all files that we were able to classify as generated in the next iteration.\\
In every iteration the amount of possible generator-patterns could be lowered by using this technique very fast until all generator-patterns were reviewed by hand and so all patterns had been found in the Qualitas Corpus.\\
We compared our results to these described in \cite{Bernwieser2014} and could confirm that our approach found all files and even. Resulting from this we concluded that our approach is as complete as it can be using the technique of suffix-tree clone-detection on the comments.\\
By using the approach on the huge random collection of open source projects we detected some more generator-patterns that were not included in the Qualitas Corpus. Nonetheless we were able to filter many generated files in the first iteration by using the generator-pattern repository what supports our assertion that the algorithm found all generator patterns that were included in the Qualitas Corpus.

\subsection{Relevance of results}

\annotation{Not sure what to write in this section.\\ Maybe how the generator-pattern repository can be used by Teamscale to lower amount of work done in analysis by excluding the generated files?}

\section{Threats to validity}
This section describes the threads that can have an impact on the validity of the results generated by our approach.
\subsection{Wrong filtering}
In Step~\ref{section:filterCloneResults} we used the regular expression shown in Listing~\ref{lst:generatorPattern}. This reduces the amount of resulting \code{CloneResult}s to a level that can be processed by a human. Our observations showed that indeed most of the generator-patterns contained the regex so that it can be considered as only a small thread.\\
Nonetheless did we found generator-patterns that didn't contain the regex. These patterns make only a very small portion of all generator-patterns so we didn't see a value in refining it. Furthermore does step~\ref{section:generateLinks} also save files and links for the not generated found \code{CloneClass}es that can be reviewed in addition to the generated ones. The problem arising is that the amount of data to review is way to high as i could be process by hand, but the ones that had the highest number of occurrences were also searched by us what revealed the patterns that didn't include the regular expression.\\
In conclusion we can say that the regular expression is a very good filter to find the generator-patterns which can be easily extended to also review the patterns that were filtered out to find all generator-patterns.

\subsection{Minimum clone length vs. irrelevant data}
a
\subsection{Representativeness of data sets}
a
\subsection{Generators without pattern}
a