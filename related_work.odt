The automatic categorization of source code is a long requested feature in the field of static analysis. Johnathan Bernwieser introduced an attempt of automating the process of categorization of source code in \cite{Bernwieser}, whereas he classified the source code in productive and test code, followed by a sub-categorization in „manually maintained“ and „automatically generated“. 
    • Especially the identification of generated code a problem
    • Generated no naming convention as in test code
    • No standartized way of marking generated code
    • Saw often marked by „generated by“ → Many false positive
    • Approached finding generated code by clone detection on generated code
    • High clone coverage bzw. higher clone density means generated classes
    • Generated classes should have highest cardinality in clone classes 
    • Implemented two mechanisms:
        ◦ Number of clones per clone class
            ▪ Worked well on the Qualitas Corpus → Often generated code with many instances
            ▪ Problem was that generated code can also be in small clone classes
            ▪ Minimum filter threshold would be really small to not lose classes
        ◦ Clone coverage per class
            ▪ Tried different clone coverage thresholds and LOC limits
            ▪ But problem is that size of java file irrelevant → No correlation to possibility of consisting of generated code
            ▪ It generated to many true negatives and thus filtered out generated code which should have been marked as generated
    • But saw that clone coverage and code generation correlate
    • But no way found on how to use correlation to automate code generator identification
    • But he saw that many code generators add comments
In contrast:
    • I‘m not doing clone detection on source code
    • But on comments
    • Find clone classes with many instances in comments
    • Observation is, that among different classes and projects the same code generators are used for the same tasks as 
        ◦ parser and scanner generation
        ◦ Data access layers
        ◦ mock objects 
        ◦ test code
    • These produce generator patterns that might be detected
